# Experiment
seed: 49
dataset: stair-lab/semi_synthetic_protein_2p12_gemma_7b
initinal_sequences: 2048
n_sequences: 1
n_restarts: 32
output_dir: ckpts/ready-SR-1seq-32rs-s49

# Acquisition function
algo: qSR # 'HES', 'qKG', 'qEI', 'qPI', 'qSR', 'qUCB', 'qMSL', 'qNIPV'
algo_ts: True
algo_n_iterations: 16
algo_lookahead_steps: 0

# Cost function
cost_spotlight_k: 100
cost_p_norm: 2.0
cost_max_noise: 1e-5
cost_discount: 0.0
cost_discount_threshold: -1.0

# Models
oracle_path: ckpts/oracle
# embedding_model_name_or_path: google/gemma-7b
embedding_model: http://hyperturing2:1337
policy_model_name_or_path: meta-llama/Meta-Llama-3-8B-Instruct
use_fast_tokenizer: True
max_new_tokens: 1024
vllm_gpu_util: 0.9
sample_size: 4 # Sampling reward value
ppo_gpu: 4
main_process_port: 29507
reward_model_port: 8007
continue_iter: 0