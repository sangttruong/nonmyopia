# Experiment
seed: 42
mutant_ver: v1
fn_ver: v2
dataset: stair-lab/semi_synthetic_protein_2p12_gemma_7b
initinal_sequences: 2048
n_sequences: 1
n_restarts: 64
output_dir: ckpts/m1f2-PI-1seq-64rs-s42

# Acquisition function
algo: qPI # 'HES', 'qKG', 'qEI', 'qPI', 'qSR', 'qUCB', 'qMSL', 'qNIPV'
algo_ts: True
algo_n_iterations: 16
algo_lookahead_steps: 0

# Cost function
cost_spotlight_k: 100
cost_p_norm: 2.0
cost_max_noise: 1e-5
cost_discount: 0.0
cost_discount_threshold: -1.0

# Models
oracle_path: ckpts/oracle
# embedding_model_name_or_path: google/gemma-7b
embedding_model: http://hyperturing1:1337
policy_model_name_or_path: meta-llama/Llama-3.2-3B-Instruct
use_fast_tokenizer: True
max_new_tokens: 1024
vllm_gpu_util: 0.9
sample_size: 4 # Sampling reward value
ppo_gpu: 4
main_process_port: 29513
reward_model_port: 8013
continue_iter: 0